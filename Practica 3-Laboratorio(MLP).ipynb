{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = [\"titanic_train\",\"iris\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeerDatos(filename : str, separa : str, header = True):\n",
    "    if (header):\n",
    "        data = pd.read_csv(filename + \".csv\", sep =separa, header = 0)\n",
    "    else:\n",
    "        data = pd.read_csv(filename+ \".csv\", sep = separa, header = None)\n",
    "    #data = data.sort_values(data.columns[1])\n",
    "    return data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalizar_Datos(data : np.array):\n",
    "    #normal = np.empty_like(data)\n",
    "    for i in range (0,np.size(data[0])):\n",
    "        media = np.mean(data[:,i])\n",
    "        desvi =np.std(data[:,i])\n",
    "        data[:,i] = (data[:,i] - media)/desvi\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crear_k_folds(data : np.array , k:int, clases: []):\n",
    "    folds = []\n",
    "    tot_clase = []\n",
    "    prop_clase = [] #Acumulado de indices\n",
    "    pre_fold = []\n",
    "\n",
    "    m = data.shape[0]# np.size(data[:,-1]) #numero de datos\n",
    "    #n = np.size(data[0])\n",
    "    for i in clases:\n",
    "        tot_clase.append(np.count_nonzero( data[:,-1] == i))\n",
    "\n",
    "    prop_clase.append(tot_clase[0])\n",
    "    for i in range (1, len(tot_clase)):\n",
    "        prop_clase.append( prop_clase[i-1] + tot_clase[i])\n",
    "\n",
    "    pos_ini = 0\n",
    "    for i in range(0, len(clases)):\n",
    "        pre_fold.append(np.array_split(data[pos_ini:prop_clase[i]], k))\n",
    "        pos_ini = prop_clase[i]\n",
    "    \n",
    "    for i in range (0,k):\n",
    "        temp = np.empty( (0,np.size(data[0])) )\n",
    "        for j in range(0,len(clases)):\n",
    "            temp = np.vstack( (temp,pre_fold[j][i]))\n",
    "        folds.append(temp)\n",
    "            \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoidal(X:np.array, theta:np.array):\n",
    "    pot = X.dot(theta)\n",
    "    return 1/(1+ np.exp(-pot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcular_Funcion_Costo(X: np.array, y:np.array):\n",
    "    #J(theta) = -1/m[ SUM( y* log(h(x)) + (1-y)*log(1-h(x)))\n",
    "    m = np.size(X[:,0]) #numero de datos\n",
    "    costo = 0\n",
    "    for i in range(0, len(X[0])):\n",
    "        costo += -1/m * ( np.sum( y[i].dot(np.log(X[i])) + (1-y[i]).dot( np.log(1-X[i]))) )\n",
    "    return costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds(D : np.array):\n",
    "    return D*(1-D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerarW( num_capas : int, dim_capas = []):\n",
    "    W = {}\n",
    "    for i in range(0,num_capas+1):\n",
    "        if (i == 0):\n",
    "            temp = np.random.randn( dim_capas[i], dim_capas[i+1] )\n",
    "            W[i] = temp\n",
    "        if (i != 0):\n",
    "            temp = np.random.randn( dim_capas[i]+1, dim_capas[i+1] )\n",
    "            W[i] = temp       \n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward (X: np.array, W : {}): \n",
    "    A = {}\n",
    "    h_l = X\n",
    "    A[0] = h_l\n",
    "    for i in range(0, len(W)):\n",
    "        if (i == len(W)-1):\n",
    "            h_l = Sigmoidal(h_l, W[i])\n",
    "        else:\n",
    "            h_l = Sigmoidal(h_l, W[i])\n",
    "            bias = np.ones( (np.size(h_l[:,0]),1) )\n",
    "            h_l = np.hstack( (bias,h_l) )\n",
    "     \n",
    "        A[i+1] = h_l   \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward (X: np.array, y: np.array, W:{}, A:{}, tasa_apren:float):\n",
    "    #Actualizacion de W (pesos) de la red por back-propagation   \n",
    "    #deriv J(theta) = a^l* delta^(l+1)\n",
    "    #g'(z) = a * (1-a)\n",
    "    m = np.size(X[:,-1])\n",
    "    delta_t = (A[len(A)-1] - y) #* ds(A[len(A)-1])\n",
    "    for i in range(len(W)-1,-1,-1):\n",
    "        R = tasa_apren* ((A[i].T.dot(delta_t))/ m)\n",
    "        if (i == len(W)-1):\n",
    "            W[i]-= R #tasa_apren* (A[i].T.dot(delta_t))/ m\n",
    "            delta_t = ds(A[i])*(delta_t.dot(W[i].T))\n",
    "        else:\n",
    "            R = R[:,1:]\n",
    "            W[i]-= R # tasa_apren* (A[i].T.dot(delta_t))/ m\n",
    "        if (i != len(W)-1  and i != 0):\n",
    "            delta_t = ds(A[i])*(delta_t[:,1:].dot(W[i].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradiente_Descendiente(X: np.array, y:np.array, W:{},\n",
    "                          num_itera:int, tasa_apren:float):\n",
    "    arr_costo = np.empty(num_itera, dtype =float)\n",
    "    A = {}\n",
    "    num_capas = len(W)\n",
    " \n",
    "    for it in range(0, num_itera):\n",
    "        A = Forward(X, W)\n",
    "        arr_costo[it] = Calcular_Funcion_Costo(A[num_capas], y)\n",
    "        Backward(X, y, W, A, tasa_apren)      \n",
    "    return A[num_capas], arr_costo, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformacionOneShot(y: np.array, clases:[]):\n",
    "    num_clases = len(clases)\n",
    "    vec_clases = np.empty((0,num_clases), dtype = int)\n",
    "    for i in y:\n",
    "        idx = clases.index(i)\n",
    "        vec = [0] * num_clases\n",
    "        vec[idx] = 1\n",
    "        vec_clases = np.vstack ((vec_clases, vec))\n",
    "    return vec_clases\n",
    "\n",
    "def OneShot_Salida(y:np.array):\n",
    "    y_cat = np.zeros_like(y)\n",
    "    max = np.argmax(y, axis = 1)\n",
    "    for i in range(0, len(max)):\n",
    "        y_cat[i,max[i]] = 1\n",
    "    return y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculoParametros(folds:[], k:int, iteraciones:int, alpha:float,\n",
    " num_clases:int, num_capa_hidden:int, num_neurona: int, clases:[]):\n",
    "    arr_costo = []\n",
    "    arr_theta = []\n",
    "    arr_test = []\n",
    "    for test_i in range(0, k):\n",
    "        test = folds[test_i] \n",
    "        train = np.zeros( (0,np.size(folds[0][0])) )\n",
    "        for train_i in range (0, k):         \n",
    "            if (train_i == test_i):\n",
    "                continue\n",
    "            else:\n",
    "                train = np.vstack( (train,folds[train_i]) )\n",
    "            \n",
    "        costo = []\n",
    "        X_train = train[:,:-1]\n",
    "        X_train = X_train.astype('float64')\n",
    "        X_train = Normalizar_Datos(X_train)\n",
    "\n",
    "        N = np.size(X_train[:,-1]) #tamaño batch\n",
    "        D_in = np.size(X_train[0]) #dimension entrada\n",
    "        D_out = num_clases\n",
    "\n",
    "        #Generacion array de capas\n",
    "        array_capas = []\n",
    "        array_capas.append(D_in)\n",
    "        for i in range(0, num_capa_hidden):\n",
    "            array_capas.append(num_neurona)\n",
    "        array_capas.append(D_out)\n",
    "\n",
    "        W = GenerarW(num_capa_hidden, array_capas)\n",
    "\n",
    "        y_train = TransformacionOneShot( train[:,-1], clases)\n",
    "\n",
    "        theta, costo, W = Gradiente_Descendiente(X_train, y_train, W, iteraciones, alpha)\n",
    "        arr_theta.append(theta)\n",
    "        arr_costo.append(costo)\n",
    "        arr_test.append(test)\n",
    "      \n",
    "    return theta, arr_costo, arr_test, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcular_Accuracy(X:np.array, y:np.array, theta:np.array):\n",
    "    y_calc = Forward(X, theta)\n",
    "    y_calc = OneShot_Salida(y_calc[len(y_calc)-1])\n",
    "    aciertos = 0\n",
    "    \n",
    "    for i in (y - y_calc):\n",
    "        if (np.count_nonzero(i) == 0):\n",
    "            aciertos += 1\n",
    "    return aciertos/np.size(y[:,0])\n",
    "    \n",
    "def PromedioAccuracy(test:np.array, theta, k, clases):\n",
    "    accu = np.zeros(k)\n",
    "    for i in range(0,k):\n",
    "        X_test = test[i][:,:-1]\n",
    "        X_test = X_test.astype('float64')\n",
    "        X_test = Normalizar_Datos(X_test)\n",
    "\n",
    "        y_test = TransformacionOneShot(test[i][:,-1], clases)\n",
    "\n",
    "        accu[i] = Calcular_Accuracy(X_test, y_test, theta)\n",
    "    return accu.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPERIMENTO 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1 TITANIC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer solo los datos necesarios\n",
    "titanic = LeerDatos(dataset[0],',')\n",
    "titanic_train = np.c_[titanic[:,0:2],titanic[:,4:6],titanic[:,-3:-2],titanic[:,-1:]]\n",
    "\n",
    "#quitamos los datos nulos\n",
    "titanic_train = pd.DataFrame(titanic_train).dropna()\n",
    "titanic_train = titanic_train.sort_values(titanic_train.columns[1])\n",
    "\n",
    "#dividimos para normalizar \n",
    "ids  = titanic_train.to_numpy()[:,0:1]\n",
    "survived  = titanic_train.to_numpy()[:,1:2]\n",
    "sex  = titanic_train.to_numpy()[:,2:3]\n",
    "age  = titanic_train.to_numpy()[:,3:4]\n",
    "fare = titanic_train.to_numpy()[:,4:5]\n",
    "embarked = titanic_train.to_numpy()[:,5:]\n",
    "\n",
    "#reemplazamos female/male por 1/0\n",
    "sex = pd.DataFrame(sex).replace({\"male\": 0, \"female\": 1})\n",
    "#reemplazamos Q/S/C por 1/2/3\n",
    "embarked = pd.DataFrame(embarked).replace({\"Q\": 1, \"S\": 2, \"C\": 3})\n",
    "\n",
    "age_nor = Normalizar_Datos(age)\n",
    "fare_nor = Normalizar_Datos(fare)\n",
    "\n",
    "#juntamos la data\n",
    "titanic_train_ = np.array(np.c_[ids,sex,age_nor,fare_nor,embarked,survived]) #id,survived,sex,age,fare,embarked \n",
    "#print(titanic_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con 1 capas y  16 neuronas\n",
      "          500       750       1000\n",
      "0.50  0.775260  0.785088  0.793527\n",
      "0.75  0.776673  0.776649  0.803342\n",
      "0.90  0.792126  0.786494  0.797699\n",
      "1.00  0.773848  0.799117  0.789307\n",
      "Con 1 capas y  32 neuronas\n",
      "          500       750       1000\n",
      "0.50  0.782287  0.790720  0.799135\n",
      "0.75  0.800518  0.801942  0.807520\n",
      "0.90  0.793497  0.804713  0.796275\n",
      "1.00  0.789313  0.808927  0.800488\n",
      "Con 1 capas y  64 neuronas\n",
      "          500       750       1000\n",
      "0.50  0.796340  0.810351  0.808956\n",
      "0.75  0.800524  0.803301  0.803295\n",
      "0.90  0.794904  0.797687  0.803283\n",
      "1.00  0.804713  0.778020  0.806102\n",
      "Con 2 capas y  16 neuronas\n",
      "          500       750       1000\n",
      "0.50  0.797693  0.787865  0.796263\n",
      "0.75  0.785082  0.801895  0.807491\n",
      "0.90  0.794850  0.797681  0.800470\n",
      "1.00  0.800476  0.815918  0.806079\n",
      "Con 2 capas y  32 neuronas\n",
      "          500       750       1000\n",
      "0.50  0.800488  0.804678  0.807491\n",
      "0.75  0.806102  0.815936  0.810310\n",
      "0.90  0.762567  0.811699  0.776584\n",
      "1.00  0.748496  0.775195  0.810280\n",
      "Con 2 capas y  64 neuronas\n",
      "          500       750       1000\n",
      "0.50  0.783622  0.818737  0.820114\n",
      "0.75  0.789254  0.775201  0.765403\n",
      "0.90  0.731689  0.735915  0.814511\n",
      "1.00  0.787854  0.792061  0.818731\n",
      "Con 3 capas y  16 neuronas\n",
      "          500       750       1000\n",
      "0.50  0.797652  0.803331  0.806102\n",
      "0.75  0.794856  0.801889  0.793462\n",
      "0.90  0.794850  0.799070  0.811704\n",
      "1.00  0.792061  0.804684  0.794862\n",
      "Con 3 capas y  32 neuronas\n",
      "          500       750       1000\n",
      "0.50  0.786447  0.804690  0.814523\n",
      "0.75  0.790672  0.785035  0.797687\n",
      "0.90  0.749926  0.806096  0.804696\n",
      "1.00  0.766839  0.751297  0.741487\n",
      "Con 3 capas y  64 neuronas\n",
      "          500       750       1000\n",
      "0.50  0.755546  0.804678  0.793432\n",
      "0.75  0.769593  0.785041  0.778002\n",
      "0.90  0.752751  0.769587  0.790655\n",
      "1.00  0.752721  0.799111  0.797681\n"
     ]
    }
   ],
   "source": [
    "clases = [0,1]\n",
    "num_clases = len(clases);k = 3\n",
    "\n",
    "#creamos los folks\n",
    "fold_titanic = Crear_k_folds(titanic_train_,k,clases)\n",
    "\n",
    "alpha = [0.5, 0.75,0.9,1.0]\n",
    "iteraciones = [500,750,1000]\n",
    "\n",
    "numero_capas = [1,2,3]\n",
    "num_neurona = [16,32,64]\n",
    "\n",
    "\n",
    "Matriz_accurracy_prom = np.empty( (len(alpha),len(iteraciones)))\n",
    "\n",
    "for nc in numero_capas:\n",
    "    for nn in num_neurona:\n",
    "        for tasa in range(0,len(alpha)):\n",
    "            for it in range(0, len(iteraciones)):\n",
    "                theta, dummy, test, W = CalculoParametros(fold_titanic, k, iteraciones[it], alpha[tasa], num_clases, nc, nn, clases)\n",
    "                Matriz_accurracy_prom[tasa,it] = PromedioAccuracy(test, W, k, clases)\n",
    "        print(\"Con\",nc,\"capas y \",nn,\"neuronas\")\n",
    "        print(pd.DataFrame(Matriz_accurracy_prom, index = alpha, columns = iteraciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 ESPECIES DE FLORES(IRIS Setosa -Iris versicolor- Iris virginica) \n",
    "#Dataset contiene 5 columnas 1-Longitud del sépalo en centímetros. 2-Ancho del sépalo en centímetros.\n",
    "#3-Longitud del pétalo en centímetros. 4-Ancho del pétalo en centímetros.\n",
    "#5-Clase.\n",
    "# url https://unipython.com/clasificacion-multiclase-de-especies-de-flores/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "especie_flores = LeerDatos(dataset[1], separa = ',')\n",
    "#quitamos los datos nulos ordenamos por clase \n",
    "especie_flores = pd.DataFrame(especie_flores).dropna()\n",
    "especie_flores = especie_flores.sort_values(especie_flores.columns[-1])\n",
    "\n",
    "\n",
    "#dividimos para normalizar \n",
    "lng_sep  = Normalizar_Datos(especie_flores.to_numpy()[:,0:1])\n",
    "anch_sep  = Normalizar_Datos(especie_flores.to_numpy()[:,1:2])\n",
    "lng_pet  = Normalizar_Datos(especie_flores.to_numpy()[:,2:3])\n",
    "anch_pet = Normalizar_Datos(especie_flores.to_numpy()[:,3:4])\n",
    "clase  = especie_flores.to_numpy()[:,4:]\n",
    "\n",
    "clase = pd.DataFrame(clase).replace({\"Iris-setosa\": 1, \"Iris-versicolor\": 2, \"Iris-virginica\": 3})\n",
    "\n",
    "\n",
    "#juntamos la data\n",
    "especie_flores = np.array(np.c_[lng_sep,anch_sep,lng_pet,anch_pet,clase]) #id,survived,sex,age,fare,embarked \n",
    "#print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con 1 capa y  8 neuronas\n",
      "           200       300       350\n",
      "0.50  0.906748  0.933284  0.926618\n",
      "0.75  0.926618  0.933284  0.946356\n",
      "0.90  0.933284  0.933284  0.940229\n",
      "1.00  0.919542  0.959837  0.940229\n",
      "Con 1 capa y  10 neuronas\n",
      "           200       300       350\n",
      "0.50  0.899804  0.926618  0.926618\n",
      "0.75  0.926618  0.933284  0.933284\n",
      "0.90  0.913415  0.926618  0.940229\n",
      "1.00  0.926618  0.953431  0.940229\n",
      "Con 1 capa y  12 neuronas\n",
      "           200       300       350\n",
      "0.50  0.919951  0.939820  0.933284\n",
      "0.75  0.926618  0.933284  0.946765\n",
      "0.90  0.933284  0.933284  0.940229\n",
      "1.00  0.933284  0.946765  0.959837\n",
      "Con 2 capa y  8 neuronas\n",
      "           200       300       350\n",
      "0.50  0.959967  0.979984  0.979984\n",
      "0.75  0.979984  0.973039  0.979984\n",
      "0.90  0.979984  0.979984  0.979984\n",
      "1.00  0.973039  0.979984  0.979984\n",
      "Con 2 capa y  10 neuronas\n",
      "           200       300       350\n",
      "0.50  0.953170  0.966503  0.979984\n",
      "0.75  0.979984  0.979984  0.979984\n",
      "0.90  0.979984  0.973448  0.979984\n",
      "1.00  0.979984  0.979984  0.979984\n",
      "Con 2 capa y  12 neuronas\n",
      "           200       300       350\n",
      "0.50  0.966912  0.979984  0.979984\n",
      "0.75  0.979984  0.979984  0.979984\n",
      "0.90  0.979984  0.979984  0.979984\n",
      "1.00  0.973448  0.979984  0.973448\n",
      "Con 3 capa y  8 neuronas\n",
      "           200       300       350\n",
      "0.50  0.973039  0.959967  0.979984\n",
      "0.75  0.979984  0.979984  0.979984\n",
      "0.90  0.979984  0.979984  0.979984\n",
      "1.00  0.973448  0.979984  0.986520\n",
      "Con 3 capa y  10 neuronas\n",
      "           200       300       350\n",
      "0.50  0.959967  0.966373  0.973039\n",
      "0.75  0.979984  0.979984  0.973039\n",
      "0.90  0.979984  0.973039  0.979984\n",
      "1.00  0.979984  0.979984  0.979575\n",
      "Con 3 capa y  12 neuronas\n",
      "           200       300       350\n",
      "0.50  0.966373  0.979984  0.973448\n",
      "0.75  0.979984  0.973448  0.979575\n",
      "0.90  0.979984  0.973448  0.979984\n",
      "1.00  0.979984  0.979984  0.973039\n"
     ]
    }
   ],
   "source": [
    "clases = [1,2,3]\n",
    "num_clases = len(clases);k = 3\n",
    "\n",
    "#creamos los folds\n",
    "fold_iris = Crear_k_folds(especie_flores,k,clases)\n",
    "\n",
    "alpha = [0.5, 0.75,0.9,1.0]\n",
    "iteraciones = [200,300,350]\n",
    "\n",
    "numero_capas = [1,2,3]\n",
    "num_neurona = [8,10,12]\n",
    "\n",
    "\n",
    "Matriz_accurracy_prom = np.empty( (len(alpha),len(iteraciones)))\n",
    "\n",
    "for nc in numero_capas:\n",
    "    for nn in num_neurona:\n",
    "        for tasa in range(0,len(alpha)):\n",
    "            for it in range(0, len(iteraciones)):\n",
    "                theta, dummy, test, W = CalculoParametros(fold_iris, k, iteraciones[it], alpha[tasa], num_clases, nc, nn, clases)\n",
    "                Matriz_accurracy_prom[tasa,it] = PromedioAccuracy(test, W, k, clases)\n",
    "        print (\"Con\",nc,\"capa y \",nn,\"neuronas\")\n",
    "        print(pd.DataFrame(Matriz_accurracy_prom, index = alpha, columns = iteraciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
